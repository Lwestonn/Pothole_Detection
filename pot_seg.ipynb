{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrjKd9nxbWcB",
        "outputId": "5be9283f-aae7-4322-d9ac-a7a7a6d30bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_DIR = \"/content/drive/My Drive/pothole_project/pothole_seg\"\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "RAW_DIR = os.path.join(DATA_DIR, \"raw\")\n",
        "PROC_DIR = os.path.join(DATA_DIR, \"processed\")\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"models\")\n",
        "RAW_YOLO_DIR = os.path.join(RAW_DIR, \"Pothole_Segmentation_YOLOv8\")\n",
        "RAW_TRAIN_IMG = os.path.join(RAW_YOLO_DIR, \"train\", \"images\")\n",
        "RAW_TRAIN_LAB = os.path.join(RAW_YOLO_DIR, \"train\", \"labels\")\n",
        "RAW_VAL_IMG   = os.path.join(RAW_YOLO_DIR, \"valid\", \"images\")\n",
        "RAW_VAL_LAB   = os.path.join(RAW_YOLO_DIR, \"valid\", \"labels\")\n",
        "TRAIN_IMG_DIR = os.path.join(PROC_DIR, \"train\", \"images\")\n",
        "TRAIN_LAB_DIR = os.path.join(PROC_DIR, \"train\", \"labels\")\n",
        "VAL_IMG_DIR   = os.path.join(PROC_DIR, \"val\", \"images\")\n",
        "VAL_LAB_DIR   = os.path.join(PROC_DIR, \"val\", \"labels\")"
      ],
      "metadata": {
        "id": "-QqsDmjLbo3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "zk6GMt20hF5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PotholeSegDataset(Dataset):\n",
        "    def __init__(self, img_dir, label_dir, transforms=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transforms = transforms\n",
        "        self.img_files = sorted([\n",
        "            f for f in os.listdir(img_dir)\n",
        "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.img_files[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        label_path = os.path.join(\n",
        "            self.label_dir,\n",
        "            os.path.splitext(img_name)[0] + \".txt\"\n",
        "        )\n",
        "\n",
        "        # --- IMAGE ---\n",
        "        img_bgr = cv2.imread(img_path)\n",
        "        if img_bgr is None:\n",
        "            raise RuntimeError(f\"Failed to read image: {img_path}\")\n",
        "\n",
        "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # ðŸ”‘ Make 100% sure it has positive, contiguous strides\n",
        "        img = np.ascontiguousarray(img_rgb)  # or img_rgb.copy()\n",
        "        h, w = img.shape[:2]\n",
        "\n",
        "        masks = []\n",
        "        boxes = []\n",
        "\n",
        "        # --- LABELS â†’ MASKS & BOXES ---\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path) as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) < 7:\n",
        "                        continue\n",
        "                    coords = np.array(list(map(float, parts[1:])))\n",
        "                    xs = coords[0::2] * w\n",
        "                    ys = coords[1::2] * h\n",
        "                    pts = np.stack([xs, ys], axis=1).astype(np.int32)\n",
        "\n",
        "                    mask = np.zeros((h, w), dtype=np.uint8)\n",
        "                    cv2.fillPoly(mask, [pts], 1)\n",
        "                    masks.append(mask)\n",
        "\n",
        "                    x_min, x_max = xs.min(), xs.max()\n",
        "                    y_min, y_max = ys.min(), ys.max()\n",
        "                    boxes.append([x_min, y_min, x_max, y_max])\n",
        "\n",
        "        if len(masks) == 0:\n",
        "            masks_arr = np.zeros((0, h, w), dtype=np.uint8)\n",
        "            boxes_arr = np.zeros((0, 4), dtype=np.float32)\n",
        "            labels_arr = np.zeros((0,), dtype=np.int64)\n",
        "        else:\n",
        "            masks_arr = np.stack(masks, axis=0)\n",
        "            boxes_arr = np.array(boxes, dtype=np.float32)\n",
        "            labels_arr = np.ones((len(masks_arr),), dtype=np.int64)\n",
        "\n",
        "        # ðŸ”‘ Make sure masks are contiguous too (just in case)\n",
        "        masks_arr = np.ascontiguousarray(masks_arr)\n",
        "        boxes_arr = np.ascontiguousarray(boxes_arr)\n",
        "        labels_arr = np.ascontiguousarray(labels_arr)\n",
        "\n",
        "        # --- NUMPY â†’ TORCH ---\n",
        "        img_t = torch.from_numpy(img).float().permute(2, 0, 1) / 255.0\n",
        "        target = {\n",
        "            \"boxes\": torch.from_numpy(boxes_arr),\n",
        "            \"labels\": torch.from_numpy(labels_arr),\n",
        "            \"masks\": torch.from_numpy(masks_arr),\n",
        "            \"image_id\": torch.tensor([idx]),\n",
        "        }\n",
        "\n",
        "        if self.transforms:\n",
        "            img_t, target = self.transforms(img_t, target)\n",
        "\n",
        "        return img_t, target\n"
      ],
      "metadata": {
        "id": "ALPYCC2pgtJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PotholeSegDataset(TRAIN_IMG_DIR, TRAIN_LAB_DIR)\n",
        "val_dataset   = PotholeSegDataset(VAL_IMG_DIR, VAL_LAB_DIR)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "arxHLgqjhJcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
      ],
      "metadata": {
        "id": "ifoQKcbMhLxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_classes = 2  # background + pothole\n",
        "\n",
        "model = maskrcnn_resnet50_fpn(weights=\"COCO_V1\")\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(5):  # start small\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for imgs, targets in train_loader:\n",
        "        imgs = [img.to(device) for img in imgs]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(imgs, targets)\n",
        "        loss = sum(loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, loss: {running_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYFkCdzdhMZT",
        "outputId": "8f1e127d-92f6-4f94-9ecc-c7da748ac19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, loss: 0.6482\n",
            "Epoch 2, loss: 0.4985\n",
            "Epoch 3, loss: 0.4266\n",
            "Epoch 4, loss: 0.3744\n",
            "Epoch 5, loss: 0.3271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = os.path.join(MODEL_DIR, \"maskrcnn_pothole.pth\")\n",
        "torch.save(model.state_dict(), weights_path)\n",
        "weights_path\n"
      ],
      "metadata": {
        "id": "irzzsYRghnUW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}